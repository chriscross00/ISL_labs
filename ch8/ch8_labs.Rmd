---
title: "ch8_labs"
author: "Christopher Chan"
date: "December 19, 2018"
output:
    rmarkdown::github_document:
        pandoc_arg: --webtex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, warning=FALSE, message=FALSE}
library(tidyverse)
library(tree)
library(ISLR)
library(randomForest)
```

##8.3.1
Preview Carseats data.
```{r}
head(Carseats)
attach(Carseats)
```

Create predictor High and add to Carseats. Needed to set the created predictor High to a factor, originally it was created as a chr
```{r}
High <- as.factor(ifelse(Sales<=8, 'No', 'Yes'))

Carseats_high <- Carseats %>%
    mutate(High)
head(Carseats_high)
```

```{r}
dim(Carseats_high)
carseats_tree <- tree(High~.-Sales, Carseats_high)
summary(carseats_tree)
```

```{r}
plot(carseats_tree)
text(carseats_tree, cex=0.75, pretty=0)
```




```{r}
set.seed(2)
train <- sample(1:nrow(Carseats), 200)
Carseats_test <- Carseats_high[-train,]
dim(Carseats_test)
High_test <- High[-train]

carseats_tree <- tree(High~.-Sales, Carseats_high, subset=train)
tree_pred <- predict(carseats_tree, Carseats_test, type='class')
table(tree_pred, High_test)

(87+59)/200 #Accuracy
```

```{r}
set.seed(3)
cv_carseats <- cv.tree(carseats_tree, FUN=prune.misclass)
names(cv_carseats)
cv_carseats
```

```{r}
par(mfrow=c(1,2))
plot(cv_carseats$size, cv_carseats$dev, type='b')
plot(cv_carseats$k, cv_carseats$dev, type='b')
```

```{r}
prune_carseats <- prune.misclass(carseats_tree, best = 9)
plot(prune_carseats)
text(prune_carseats, pretty=0)
```

```{r}
prune_pred <- predict(prune_carseats, Carseats_test, type='class')
table(prune_pred, High_test)

(101+74)/200 #accuracy
```

##8.3.2
```{r, message=FALSE}
library(MASS)
```

```{r}
set.seed(1)

train <- sample(1:nrow(Boston), nrow(Boston)/2)
tree_bos <- tree(medv~., Boston, subset=train)
summary(tree_bos)
```

```{r}
plot(tree_bos)
text(tree_bos, pretty=0, cex=0.75)
```

```{r}
cv_bos <- cv.tree(tree_bos)
plot(cv_bos$size, cv_bos$dev, type='b')
```

```{r}
prune_bos <- prune.tree(tree_bos, best=5)
plot(prune_bos)
text(prune_bos, pretty=0)
```

```{r}
yhat <- predict(tree_bos, newdata=Boston[-train,])
test_bos <- Boston[-train, 'medv'] 

plot(yhat, test_bos)
abline(0, 1)
mean((yhat-test_bos)^2)
```


##8.3.3
The randomForest() can perform both bagging and random forest. By setting $m=p$ we prevent the random forest from occuring, instead only bagging occurs. This is what happens in the following code, mtry=13, so all the predictor variables are considered for each node.
```{r}
set.seed(1)

bag_boston <- randomForest(medv~., Boston, subset=train, mtry=13, importance=T)
bag_boston
```

Accuracy of bagging model.
```{r}
yhat_bag <- predict(bag_boston, newdata=Boston[-train,])

plot(yhat_bag, test_bos)
abline(0,1)

mean((yhat_bag - test_bos)^2)
```
























