---
title: "ch6_lab"
author: "Christopher Chan"
date: "December 12, 2018"
output:
    rmarkdown::github_document:
    pandoc_arg: --webtex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, warning=FALSE, message=FALSE}
library(tidyverse)
library(forecast)
library(ISLR)
library(leaps)
```
*Note: I'm going to try my best to use the tidyverse package for everything, just to get use to the environment.


##6.5.1
Getting a sense of the data, Hitters
```{r}
dim(Hitters)
colnames(Hitters)
glimpse(Hitters)
summary(Hitters)
```

Dropping rows that are missing the salary value. Base R uses na.omit.
```{r}
sum(is.na(Hitters$Salary))

Hitters <- drop_na(Hitters, Salary)
dim(Hitters)
```

A model with default nvmax, nvmax=8
```{r}
regfit_norm <- regsubsets(Salary~., Hitters)
summary(regfit_full)
```

While I can use the general lm() to create a GLM with 19 variables, only 19 because Salary is a response variable, it only returns 1 model. The $R^2$ should be the same as the regsubsets model with 19 variables. The advantage of using regsubsets with nvmax = 19 is that we get more models, each with a varying amount of variables. Below is the lm() of Hitters with Salary as the response variable.
```{r}
test <- lm(Salary~., Hitters)
summary(test)
```

regsubsets() with nvmax=19. 
```{r}
regfit_full <- regsubsets(Salary~., Hitters, nvmax=19)
```

summary() returns all the GLM created. We are trying to find the best model. Notice that as we add variables $R^2$ increases.
```{r}
regfit_best <- summary(regfit_full)
head(regfit_best)
regfit_best$rsq
```

```{r}

```






















