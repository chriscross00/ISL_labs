---
title: "ch6_lab2"
author: "Christoper Chan"
date: "December 22, 2018"
output: 
    rmarkdown::github_document:
        pandoc_arg: --webtex
    
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, warning=FALSE, message=FALSE}
library(tidyverse)
library(forecast)
library(ISLR)
library(leaps)
library(glmnet)
```

#Lab 2: Ridge and Lasso Regression
##6.6.1
Creating a model.matrix of our Hitters data. Because rows with NA are dropped in the model.matrix function the y variable must also drop rows with NA.
```{r}
x <- model.matrix(Salary~., Hitters)[,-1]
y <- Hitters$Salary %>%
    na.omit()
```

Creating an array of length 100 equally spaced distances between 10^-2 and 10^10. This will be our $\lambda$ values that we'll use for the section. We then run ridge regression on our grid.
```{r}
grid <- 10^seq(10,-2, length=100)
ridge_mod <- glmnet(x, y, alpha=0, lambda=grid)
```

This is messing around with different lambda values, showing that high $\lambda$ values yield low coef and low $\lambda$ values give high coef.
```{r}
ridge_mod$lambda[70]
coef(ridge_mod)[,70]
```

Running our ridge regression model on a set $\lambda$, in this case 50.
```{r}
predict(ridge_mod, s=50, type='coefficients')[1:20,]
```

Validating our data via cross validation.
```{r}
set.seed(1)

train <- sample(1:nrow(x), nrow(x)/2)
test <- (-train)
y_test <- y[test]
```

Running cross validation and calculating the MSE
```{r}
ridge_mod <- glmnet(x[train,], y[train], alpha=0, lambda=grid, thresh=1e-12)
ridge_pred <- predict(ridge_mod, s=4, newx=x[test,])
mean((ridge_pred - y_test)^2)
```

Testing if $\lambda = 0$ yields a better result than $\lambda = 4$, ie if ridge regression has any effect. 
```{r}
ridge_pred_null <- predict(ridge_mod, s=0, newx=x[test,])
mean((ridge_pred_null - y_test)^2)

lm(y~x, subset=train)
predict(ridge_mod, s=0, type='coefficients')[1:20,]
```
Based on the MSE we see that with a $\lambda$ of 4 ridge regression yields a better lm than without ridge regression.


```{r}
set.seed(2)

cv_out <- cv.glmnet(x[train,], y[train], alpha=0)
plot(cv_out)

best_lam <- cv_out$lambda.min
best_lam
```

Running our model with the best $\lambda$ yields a slightly lower MSE than with the $\lambda$ above.
```{r}
ridge_pred <- predict(ridge_mod, s=best_lam, newx=x[test,])
mean((ridge_pred-y_test)^2)
```

Running cross-validation and our best $\lamda$ to get the coef.
```{r}
out <- glmnet(x, y, alpha=0)
predict(out, type='coefficients', s=best_lam)
```

##6.2.2 Lasso






























